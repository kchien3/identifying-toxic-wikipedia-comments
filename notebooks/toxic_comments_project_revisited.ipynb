{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plotting\n",
    "# import matplotlib.pyplot as plt\n",
    "# array operations\n",
    "import numpy as np\n",
    "# reading in data\n",
    "import pandas as pd\n",
    "# distributions\n",
    "import scipy.stats as stats\n",
    "# machine learning\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB #very fast\n",
    "from sklearn.linear_model import SGDClassifier #very fast\n",
    "from sklearn.ensemble import ExtraTreesClassifier #14m, average precision: 0.4033\n",
    "from sklearn.ensemble import RandomForestClassifier #>14m\n",
    "from sklearn.ensemble import GradientBoostingClassifier #45m\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# system time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    # timing the training of the classifier\n",
    "    print('_' * 72, \n",
    "          \"Training: \", \n",
    "          clf, \n",
    "          sep='\\n')\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "    print(f\"train time: {train_time:.4f}s\")\n",
    "\n",
    "    # timing the prediction of the classifier\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(X_val)\n",
    "    predict_time = time.time() - t0\n",
    "    print(f\"predict time: {predict_time:.4f}s\")\n",
    "\n",
    "    # calculating average precision (the area under the precision-recall curve)\n",
    "    score = metrics.average_precision_score(y_val, pred)\n",
    "    print(f\"average precision: {score:.4f}\")\n",
    "\n",
    "    # study model coefficients\n",
    "    coefs = None\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        coefs = clf.coef_\n",
    "    elif hasattr(clf, 'feature_importances_'):\n",
    "        coefs = clf.feature_importances_.reshape(1, -1)\n",
    "        \n",
    "    if isinstance(coefs, np.ndarray):\n",
    "        print(f\"dimensionality: {coefs.shape[1]}\", # number of coefficients\n",
    "              f\"density: {density(coefs)}\", # non-zero coefficient density\n",
    "              \"top 10 words indicating toxic:\",\n",
    "              sep='\\n')\n",
    "        # indices of largest 10 coefficients\n",
    "        top10 = np.argsort(coefs[0])[-10:]\n",
    "        # top 10 features indicating toxic\n",
    "        print(feature_names[top10])\n",
    "\n",
    "        print(\"top 10 words indicating not toxic:\")\n",
    "        # indices of smallest 10 coefficients\n",
    "        btm10 = np.argsort(coefs[0])[:10]\n",
    "        # top 10 features indicating not toxic\n",
    "        print(feature_names[btm10])\n",
    "\n",
    "        # classification report\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_val, pred, target_names=['not toxic', 'toxic']))\n",
    "        \n",
    "        # confusion matrix on validation set\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_val, pred))\n",
    "    \n",
    "    # sklearn model name\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    \n",
    "    return clf, clf_descr, score, train_time, predict_time\n",
    "\n",
    "\n",
    "# report best scores\n",
    "def report(results, n_top=20):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(f\"Model with rank: {i}\", \n",
    "                  f\"Mean validation score: {results['mean_test_score'][candidate]:.4f} \"\n",
    "                  f\"(std: {results['std_test_score'][candidate]:.4f})\",\n",
    "                  f\"Mean fit time: {results['mean_fit_time'][candidate]:.4f} \"\n",
    "                  f\"(std: {results['std_fit_time'][candidate]:.4f})\",\n",
    "                  f\"Mean score time: {results['mean_score_time'][candidate]:.4f} \"\n",
    "                  f\"(std: {results['std_score_time'][candidate]:.4f})\",\n",
    "                  f\"Parameters: {results['params'][candidate]}\", \n",
    "                  sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# NMSLIB approximate-nearest neighbors sklearn wrapper\n",
    "# NMSLIB: https://github.com/nmslib/nmslib\n",
    "# Wrapper author: Davi Sidarta-Oliveira\n",
    "# School of Medical Sciences,University of Campinas,Brazil\n",
    "# contact: davisidarta@gmail.com\n",
    "######################################\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from scipy.sparse import csr_matrix, find, issparse\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    import nmslib\n",
    "except ImportError:\n",
    "    print(\"The package 'nmslib' is required. Please install it 'with pip3 install nmslib'.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "class NMSlibTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Wrapper for using nmslib as sklearn's KNeighborsTransformer. This implements\n",
    "    an escalable approximate k-nearest-neighbors graph on spaces defined by nmslib.\n",
    "    Read more about nmslib and its various available metrics at\n",
    "    https://github.com/nmslib/nmslib.\n",
    "    Calling 'nn <- NMSlibTransformer()' initializes the class with\n",
    "     neighbour search parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_neighbors: int (optional, default 30)\n",
    "        number of nearest-neighbors to look for. In practice,\n",
    "        this should be considered the average neighborhood size and thus vary depending\n",
    "        on your number of features, samples and data intrinsic dimensionality. Reasonable values\n",
    "        range from 5 to 100. Smaller values tend to lead to increased graph structure\n",
    "        resolution, but users should beware that a too low value may render granulated and vaguely\n",
    "        defined neighborhoods that arise as an artifact of downsampling. Defaults to 30. Larger\n",
    "        values can slightly increase computational time.\n",
    "    metric: str (optional, default 'cosine')\n",
    "        accepted NMSLIB metrics. Defaults to 'cosine'. Accepted metrics include:\n",
    "        -'sqeuclidean'\n",
    "        -'euclidean'\n",
    "        -'l1'\n",
    "        -'lp' - requires setting the parameter `p`\n",
    "        -'cosine'\n",
    "        -'angular'\n",
    "        -'negdotprod'\n",
    "        -'levenshtein'\n",
    "        -'hamming'\n",
    "        -'jaccard'\n",
    "        -'jansen-shan'\n",
    "    method: str (optional, default 'hsnw')\n",
    "        approximate-neighbor search method. Available methods include:\n",
    "                -'hnsw' : a Hierarchical Navigable Small World Graph.\n",
    "                -'sw-graph' : a Small World Graph.\n",
    "                -'vp-tree' : a Vantage-Point tree with a pruning rule adaptable to non-metric distances.\n",
    "                -'napp' : a Neighborhood APProximation index.\n",
    "                -'simple_invindx' : a vanilla, uncompressed, inverted index, which has no parameters.\n",
    "                -'brute_force' : a brute-force search, which has no parameters.\n",
    "        'hnsw' is usually the fastest method, followed by 'sw-graph' and 'vp-tree'.\n",
    "    n_jobs: int (optional, default 1)\n",
    "        number of threads to be used in computation. Defaults to 1. The algorithm is highly\n",
    "        scalable to multi-threading.\n",
    "    M: int (optional, default 30)\n",
    "        defines the maximum number of neighbors in the zero and above-zero layers during HSNW\n",
    "        (Hierarchical Navigable Small World Graph). However, the actual default maximum number\n",
    "        of neighbors for the zero layer is 2*M.  A reasonable range for this parameter\n",
    "        is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320.\n",
    "        HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib.\n",
    "    efC: int (optional, default 100)\n",
    "        A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph\n",
    "        and leads to higher accuracy of search. However this also leads to longer indexing times.\n",
    "        A reasonable range for this parameter is 50-2000.\n",
    "    efS: int (optional, default 100)\n",
    "        A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the\n",
    "        expense of longer retrieval time. A reasonable range for this parameter is 100-2000.\n",
    "    dense: bool (optional, default False)\n",
    "        Whether to force the algorithm to use dense data, such as np.ndarrays and pandas DataFrames.\n",
    "    Returns\n",
    "    ---------\n",
    "    Class for really fast approximate-nearest-neighbors search.\n",
    "    Example\n",
    "    -------------\n",
    "    import numpy as np\n",
    "    from sklearn.datasets import load_digits\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from dbmap.ann import NMSlibTransformer\n",
    "    #\n",
    "    # Load the MNIST digits data, convert to sparse for speed\n",
    "    digits = load_digits()\n",
    "    data = csr_matrix(digits)\n",
    "    #\n",
    "    # Start class with parameters\n",
    "    nn = NMSlibTransformer()\n",
    "    nn = nn.fit(data)\n",
    "    #\n",
    "    # Obtain kNN graph\n",
    "    knn = nn.transform(data)\n",
    "    #\n",
    "    # Obtain kNN indices, distances and distance gradient\n",
    "    ind, dist, grad = nn.ind_dist_grad(data)\n",
    "    #\n",
    "    # Test for recall efficiency during approximate nearest neighbors search\n",
    "    test = nn.test_efficiency(data)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_neighbors=30,\n",
    "                 metric='cosine',\n",
    "                 method='hnsw',\n",
    "                 n_jobs=10,\n",
    "                 p=None,\n",
    "                 M=30,\n",
    "                 efC=100,\n",
    "                 efS=100,\n",
    "                 dense=False,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.method = method\n",
    "        self.metric = metric\n",
    "        self.n_jobs = n_jobs\n",
    "        self.p = p\n",
    "        self.M = M\n",
    "        self.efC = efC\n",
    "        self.efS = efS\n",
    "        self.space = self.metric\n",
    "\n",
    "        self.dense = dense\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, data, y=None):\n",
    "        # see more metrics in the manual\n",
    "        # https://github.com/nmslib/nmslib/tree/master/manual\n",
    "\n",
    "        if self.dense:\n",
    "            self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                       space=self.space,\n",
    "                                       data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "\n",
    "        else:\n",
    "            if issparse(data) == True:\n",
    "                if self.verbose:\n",
    "                    print('Sparse input. Proceding without converting...')\n",
    "                if isinstance(data, np.ndarray):\n",
    "                    data = csr_matrix(data)\n",
    "            if issparse(data) == False:\n",
    "                if self.verbose:\n",
    "                    print('Input data is ' + str(type(data)) + ' .Converting input to sparse...')\n",
    "                import pandas as pd\n",
    "                if isinstance(data, pd.DataFrame):\n",
    "                    data = csr_matrix(data.values.T)\n",
    "\n",
    "        index_time_params = {'M': self.M, 'indexThreadQty': self.n_jobs, 'efConstruction': self.efC, 'post': 0}\n",
    "\n",
    "        if issparse(data) and (not self.dense) and (not isinstance(data, np.ndarray)):\n",
    "            if self.metric not in ['levenshtein', 'hamming', 'jansen-shan', 'jaccard']:\n",
    "                self.space = {\n",
    "                    'sqeuclidean': 'l2_sparse',\n",
    "                    'euclidean': 'l2_sparse',\n",
    "                    'cosine': 'cosinesimil_sparse_fast',\n",
    "                    'lp': 'lp_sparse',\n",
    "                    'l1_sparse': 'l1_sparse',\n",
    "                    'linf_sparse': 'linf_sparse',\n",
    "                    'angular_sparse': 'angulardist_sparse_fast',\n",
    "                    'negdotprod_sparse': 'negdotprod_sparse_fast',\n",
    "                }[self.metric]\n",
    "                if self.metric == 'lp' and selp.p is None:\n",
    "                    print('Metric set to `lp` but `p` not set. Setting `p` as 0.5.')\n",
    "\n",
    "                if self.metric == 'lp' and selp.p is not None:\n",
    "                    self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                               space=self.space,\n",
    "                                               space_params={'p': self.p},\n",
    "                                               data_type=nmslib.DataType.SPARSE_VECTOR)\n",
    "                else:\n",
    "                    self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                               space=self.space,\n",
    "                                               data_type=nmslib.DataType.SPARSE_VECTOR)\n",
    "            else:\n",
    "                print('Metric ' + self.metric + 'available for string data only. Trying to compute distances...')\n",
    "                data = data.toarray()\n",
    "                self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                           space=self.space,\n",
    "                                           data_type=nmslib.DataType.OBJECT_AS_STRING)\n",
    "        else:\n",
    "            self.space = {\n",
    "                'sqeuclidean': 'l2',\n",
    "                'euclidean': 'l2',\n",
    "                'cosine': 'cosinesimil',\n",
    "                'lp': 'lp',\n",
    "                'l1': 'l1',\n",
    "                'linf': 'linf',\n",
    "                'angular': 'angulardist',\n",
    "                'negdotprod': 'negdotprod',\n",
    "                'levenshtein': 'leven',\n",
    "                'hamming': 'bit_hamming',\n",
    "                'jaccard': 'bit_jaccard',\n",
    "                'jansen-shan': 'jsmetrfastapprox'\n",
    "            }[self.metric]\n",
    "            if self.metric == 'lp':\n",
    "                self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                           space=self.space,\n",
    "                                           space_params={'p': self.p},\n",
    "                                           data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "            else:\n",
    "                self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                           space=self.space,\n",
    "                                           data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "\n",
    "        self.nmslib_.addDataPointBatch(data)\n",
    "        start = time.time()\n",
    "        self.nmslib_.createIndex(index_time_params)\n",
    "        end = time.time()\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Index-time parameters', 'M:', self.M, 'n_threads:', self.n_jobs, 'efConstruction:', self.efC,\n",
    "                  'post:0')\n",
    "            print('Indexing time = %f (sec)' % (end - start))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        start = time.time()\n",
    "        n_samples_transform = data.shape[0]\n",
    "        query_time_params = {'efSearch': self.efS}\n",
    "        if self.verbose:\n",
    "            print('Query-time parameter efSearch:', self.efS)\n",
    "        self.nmslib_.setQueryTimeParams(query_time_params)\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        self.n_neighbors = self.n_neighbors + 1\n",
    "\n",
    "        results = self.nmslib_.knnQueryBatch(data, k=self.n_neighbors,\n",
    "                                             num_threads=self.n_jobs)\n",
    "\n",
    "        indices, distances = zip(*results)\n",
    "        indices, distances = np.vstack(indices), np.vstack(distances)\n",
    "\n",
    "        query_qty = data.shape[0]\n",
    "\n",
    "        if self.metric == 'sqeuclidean':\n",
    "            distances **= 2\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * self.n_neighbors + 1,\n",
    "                           self.n_neighbors)\n",
    "        kneighbors_graph = csr_matrix((distances.ravel(), indices.ravel(),\n",
    "                                       indptr), shape=(n_samples_transform,\n",
    "                                                       n_samples_transform))\n",
    "        end = time.time()\n",
    "        if self.verbose:\n",
    "            print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty, self.n_jobs * float(end - start) / query_qty))\n",
    "\n",
    "        return kneighbors_graph\n",
    "\n",
    "    def ind_dist_grad(self, data, return_grad=True, return_graph=True):\n",
    "\n",
    "        start = time.time()\n",
    "        n_samples_transform = data.shape[0]\n",
    "        query_time_params = {'efSearch': self.efS}\n",
    "        if self.verbose:\n",
    "            print('Query-time parameter efSearch:', self.efS)\n",
    "        self.nmslib_.setQueryTimeParams(query_time_params)\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        self.n_neighbors = self.n_neighbors + 1\n",
    "        results = self.nmslib_.knnQueryBatch(data, k=self.n_neighbors,\n",
    "                                             num_threads=self.n_jobs)\n",
    "        indices, distances = zip(*results)\n",
    "        indices, distances = np.vstack(indices), np.vstack(distances)\n",
    "\n",
    "        query_qty = data.shape[0]\n",
    "\n",
    "        if self.metric == 'sqeuclidean':\n",
    "            distances **= 2\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * self.n_neighbors + 1,\n",
    "                           self.n_neighbors)\n",
    "        kneighbors_graph = csr_matrix((distances.ravel(), indices.ravel(),\n",
    "                                       indptr), shape=(n_samples_transform,\n",
    "                                                       n_samples_transform))\n",
    "        if return_grad:\n",
    "            x, y, dists = find(kneighbors_graph)\n",
    "\n",
    "            # Define gradients\n",
    "            grad = []\n",
    "            if self.metric not in ['sqeuclidean', 'euclidean', 'cosine', 'linf']:\n",
    "                print('Gradient undefined for metric \\'' + self.metric + '\\'. Returning empty array.')\n",
    "\n",
    "            if self.metric == 'cosine':\n",
    "                norm_x = 0.0\n",
    "                norm_y = 0.0\n",
    "                for i in range(x.shape[0]):\n",
    "                    norm_x += x[i] ** 2\n",
    "                    norm_y += y[i] ** 2\n",
    "                if norm_x == 0.0 and norm_y == 0.0:\n",
    "                    grad = np.zeros(x.shape)\n",
    "                elif norm_x == 0.0 or norm_y == 0.0:\n",
    "                    grad = np.zeros(x.shape)\n",
    "                else:\n",
    "                    grad = -(x * dists - y * norm_x) / np.sqrt(norm_x ** 3 * norm_y)\n",
    "\n",
    "            if self.metric == 'euclidean':\n",
    "                grad = x - y / (1e-6 + np.sqrt(dists))\n",
    "\n",
    "            if self.metric == 'sqeuclidean':\n",
    "                grad = x - y / (1e-6 + dists)\n",
    "\n",
    "            if self.metric == 'linf':\n",
    "                result = 0.0\n",
    "                max_i = 0\n",
    "                for i in range(x.shape[0]):\n",
    "                    v = np.abs(x[i] - y[i])\n",
    "                    if v > result:\n",
    "                        result = dists\n",
    "                        max_i = i\n",
    "                grad = np.zeros(x.shape)\n",
    "                grad[max_i] = np.sign(x[max_i] - y[max_i])\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if self.verbose:\n",
    "            print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty, self.n_jobs * float(end - start) / query_qty))\n",
    "\n",
    "        if return_graph and return_grad:\n",
    "            return indices, distances, grad, kneighbors_graph\n",
    "        if return_graph and not return_grad:\n",
    "            return indices, distances, kneighbors_graph\n",
    "        if not return_graph and return_grad:\n",
    "            return indices, distances, grad\n",
    "        if not return_graph and not return_grad:\n",
    "            return indices, distances\n",
    "\n",
    "    def test_efficiency(self, data, data_use=0.1):\n",
    "        \"\"\"Test if NMSlibTransformer and KNeighborsTransformer give same results\n",
    "        \"\"\"\n",
    "        self.data_use = data_use\n",
    "\n",
    "        query_qty = data.shape[0]\n",
    "\n",
    "        (dismiss, test) = train_test_split(data, test_size=self.data_use)\n",
    "        query_time_params = {'efSearch': self.efS}\n",
    "        if self.verbose:\n",
    "            print('Setting query-time parameters', query_time_params)\n",
    "        self.nmslib_.setQueryTimeParams(query_time_params)\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        self.n_neighbors = self.n_neighbors + 1\n",
    "        start = time.time()\n",
    "        ann_results = self.nmslib_.knnQueryBatch(data, k=self.n_neighbors,\n",
    "                                                 num_threads=self.n_jobs)\n",
    "        end = time.time()\n",
    "        if self.verbose:\n",
    "            print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty, self.n_jobs * float(end - start) / query_qty))\n",
    "\n",
    "        # Use sklearn for exact neighbor search\n",
    "        start = time.time()\n",
    "        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors,\n",
    "                                metric='cosine',\n",
    "                                algorithm='brute').fit(data)\n",
    "        knn = nbrs.kneighbors(data)\n",
    "        end = time.time()\n",
    "        if self.verbose:\n",
    "            print('brute-force gold-standart kNN time total=%f (sec), per query=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty))\n",
    "\n",
    "        recall = 0.0\n",
    "        for i in range(0, query_qty):\n",
    "            correct_set = set(knn[1][i])\n",
    "            ret_set = set(ann_results[i][0])\n",
    "            recall = recall + float(len(correct_set.intersection(ret_set))) / len(correct_set)\n",
    "        recall = recall / query_qty\n",
    "        print('kNN recall %f' % recall)\n",
    "\n",
    "    def update_search(self, n_neighbors):\n",
    "        \"\"\"\n",
    "        Updates number of neighbors for kNN distance computation.\n",
    "        Parameters\n",
    "        -----------\n",
    "        n_neighbors: New number of neighbors to look for.\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training and testing csvs and testing labels into pandas DataFrames\n",
    "df_train = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/test.csv\")\n",
    "df_test_labels = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/test_labels.csv\")\n",
    "# merge testing set and testing labels\n",
    "df_test = pd.merge(df_test, df_test_labels)\n",
    "# exclude comments with a label of -1, which was not used for competition scoring\n",
    "df_test = df_test[df_test.toxic != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training set into training and validation set\n",
    "df_train, df_val = train_test_split(df_train, random_state=1935, stratify=df_train.toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strip_accents ascii doesn't improve performance\n",
    "strip_accents unicode doesn't improve performance\n",
    "stop_words reduces performance\n",
    "CountVectorizer is worse that TfidfVectorizer\n",
    "sublinear_tf improves performance\n",
    "<50000 features reduces performance 198000\n",
    "squared_hinge loss reduces performance\n",
    "perceptron loss reduces performance\n",
    "including 2+-grams reduces performance\n",
    "min_df=2-4 best performance\n",
    "max_df=0.5+ doesn't improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tf-idf vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    min_df=4,\n",
    ")\n",
    "\n",
    "# vectorize data rename labels\n",
    "X_train = vectorizer.fit_transform(df_train.comment_text)\n",
    "y_train = df_train.toxic\n",
    "\n",
    "X_val = vectorizer.transform(df_val.comment_text)\n",
    "y_val = df_val.toxic\n",
    "\n",
    "X_test = vectorizer.transform(df_test.comment_text)\n",
    "y_test = df_test.toxic\n",
    "\n",
    "# get vocabulary\n",
    "feature_names = np.asarray(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   47.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 253 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 255 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 262 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 269 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 270 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 271 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 274 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 275 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 277 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 279 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 282 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 283 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 286 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 287 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 291 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 294 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 295 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 298 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 299 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 301 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 302 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 303 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 307 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 310 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 311 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 313 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 315 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 316 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 318 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 319 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 323 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 324 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 325 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 326 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 327 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 329 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 331 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 332 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 335 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 336 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 337 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 339 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 340 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 342 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 343 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 345 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 347 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 348 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 351 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 355 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 356 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 358 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 359 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 362 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 363 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 364 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 365 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 366 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 367 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 369 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 371 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 372 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 374 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 375 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 377 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 378 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 379 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 380 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 381 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 383 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 385 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 387 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 390 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 391 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 392 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 393 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 394 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 395 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 398 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 399 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 400 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 401 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 403 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 404 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 406 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 407 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 408 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 409 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 410 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 411 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 412 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 414 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 415 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 417 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 419 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 420 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 422 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 423 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 425 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 427 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 431 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 433 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 435 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 439 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 441 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 443 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 444 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 445 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 447 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 451 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 452 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 453 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 454 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 458 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 459 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 462 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 463 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 464 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 467 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 468 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 469 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 470 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 471 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 475 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 476 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 477 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 478 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 479 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 481 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 483 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 485 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 486 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 487 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 489 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 490 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 491 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 493 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 494 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 495 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 497 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 499 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 501 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 502 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 503 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 505 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 506 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 507 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 509 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 510 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 511 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 514 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 515 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 516 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 517 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 519 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 522 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 523 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 524 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 525 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 526 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 527 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed:  3.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 531 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 532 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 533 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 534 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 535 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 539 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 540 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 541 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 542 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 543 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 544 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 545 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 547 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 548 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 549 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 550 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 551 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 553 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 555 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 556 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 557 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 558 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 559 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 560 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 561 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 563 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 565 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 566 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 567 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 568 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 569 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 571 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 572 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 573 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 574 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 575 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 577 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 578 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 579 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 580 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 582 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 583 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 584 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 585 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 586 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 587 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 588 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 590 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 591 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 593 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 594 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 595 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 596 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 598 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 599 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 601 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 602 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 603 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 604 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 607 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 609 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 610 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 611 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 613 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 615 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 617 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 618 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 619 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 620 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 621 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 622 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 623 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 625 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 638 out of 640 | elapsed:  4.0min remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:  4.0min finished\n",
      "-- Epoch 1\n",
      "Norm: 178.50, NNZs: 3137, Bias: -0.799189, T: 80782, Avg. loss: 0.322944\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 149.78, NNZs: 2827, Bias: -0.858212, T: 161564, Avg. loss: 0.162094\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 136.79, NNZs: 2784, Bias: -0.888174, T: 242346, Avg. loss: 0.150399\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 129.20, NNZs: 2759, Bias: -0.901344, T: 323128, Avg. loss: 0.148903\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 124.18, NNZs: 2780, Bias: -0.872858, T: 403910, Avg. loss: 0.146500\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 120.36, NNZs: 2790, Bias: -0.906557, T: 484692, Avg. loss: 0.146263\n",
      "Total training time: 0.90 seconds.\n",
      "Convergence after 6 epochs took 0.96 seconds\n",
      "RandomizedSearchCV took 239.50 seconds for 128 candidates\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.8590 (std: 0.0060)\n",
      "Mean fit time: 3.1630 (std: 0.6066)\n",
      "Mean score time: 0.0340 (std: 0.0114)\n",
      "Parameters: {'alpha': 3.122038253095453e-05, 'l1_ratio': 0.5916730265839458, 'loss': 'hinge'}\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.8588 (std: 0.0057)\n",
      "Mean fit time: 3.1194 (std: 0.3405)\n",
      "Mean score time: 0.0278 (std: 0.0062)\n",
      "Parameters: {'alpha': 9.286068726061531e-06, 'l1_ratio': 0.47338549507714167, 'loss': 'log'}\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.8582 (std: 0.0050)\n",
      "Mean fit time: 2.7638 (std: 0.1901)\n",
      "Mean score time: 0.0244 (std: 0.0021)\n",
      "Parameters: {'alpha': 1.2446407753804878e-05, 'l1_ratio': 0.4922882085853024, 'loss': 'log'}\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.8578 (std: 0.0052)\n",
      "Mean fit time: 2.7214 (std: 0.1971)\n",
      "Mean score time: 0.0266 (std: 0.0073)\n",
      "Parameters: {'alpha': 8.760445775402615e-06, 'l1_ratio': 0.5150809115511314, 'loss': 'log'}\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.8577 (std: 0.0056)\n",
      "Mean fit time: 2.2335 (std: 0.2101)\n",
      "Mean score time: 0.0180 (std: 0.0064)\n",
      "Parameters: {'alpha': 8.666144790053072e-06, 'l1_ratio': 0.19669645099211308, 'loss': 'log'}\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.8577 (std: 0.0059)\n",
      "Mean fit time: 2.8852 (std: 0.3731)\n",
      "Mean score time: 0.0288 (std: 0.0031)\n",
      "Parameters: {'alpha': 1.5725239786843758e-05, 'l1_ratio': 0.5846062534824146, 'loss': 'log'}\n",
      "Model with rank: 7\n",
      "Mean validation score: 0.8573 (std: 0.0029)\n",
      "Mean fit time: 2.5960 (std: 0.1591)\n",
      "Mean score time: 0.0258 (std: 0.0050)\n",
      "Parameters: {'alpha': 2.1745230002190914e-05, 'l1_ratio': 0.6763796097369464, 'loss': 'hinge'}\n",
      "Model with rank: 8\n",
      "Mean validation score: 0.8573 (std: 0.0050)\n",
      "Mean fit time: 3.0778 (std: 0.1565)\n",
      "Mean score time: 0.0242 (std: 0.0020)\n",
      "Parameters: {'alpha': 1.5960182680043032e-05, 'l1_ratio': 0.3928220392050533, 'loss': 'log'}\n",
      "Model with rank: 9\n",
      "Mean validation score: 0.8571 (std: 0.0045)\n",
      "Mean fit time: 2.7431 (std: 0.1518)\n",
      "Mean score time: 0.0246 (std: 0.0053)\n",
      "Parameters: {'alpha': 1.0111208482878e-05, 'l1_ratio': 0.30360879010897746, 'loss': 'log'}\n",
      "Model with rank: 10\n",
      "Mean validation score: 0.8570 (std: 0.0055)\n",
      "Mean fit time: 3.1399 (std: 0.4262)\n",
      "Mean score time: 0.0296 (std: 0.0125)\n",
      "Parameters: {'alpha': 8.08817327164599e-06, 'l1_ratio': 0.24230932166042796, 'loss': 'log'}\n",
      "Model with rank: 11\n",
      "Mean validation score: 0.8568 (std: 0.0054)\n",
      "Mean fit time: 2.5532 (std: 0.2601)\n",
      "Mean score time: 0.0242 (std: 0.0024)\n",
      "Parameters: {'alpha': 3.5996964818394766e-05, 'l1_ratio': 0.5736144661198943, 'loss': 'hinge'}\n",
      "Model with rank: 12\n",
      "Mean validation score: 0.8568 (std: 0.0059)\n",
      "Mean fit time: 3.1924 (std: 0.1726)\n",
      "Mean score time: 0.0298 (std: 0.0096)\n",
      "Parameters: {'alpha': 8.401246340026837e-06, 'l1_ratio': 0.7218940895563624, 'loss': 'log'}\n",
      "Model with rank: 13\n",
      "Mean validation score: 0.8567 (std: 0.0051)\n",
      "Mean fit time: 2.6892 (std: 0.2128)\n",
      "Mean score time: 0.0240 (std: 0.0048)\n",
      "Parameters: {'alpha': 1.923673821636001e-05, 'l1_ratio': 0.6920898499372358, 'loss': 'log'}\n",
      "Model with rank: 14\n",
      "Mean validation score: 0.8566 (std: 0.0060)\n",
      "Mean fit time: 2.9863 (std: 0.2019)\n",
      "Mean score time: 0.0294 (std: 0.0058)\n",
      "Parameters: {'alpha': 1.1855218546201605e-05, 'l1_ratio': 0.3568461238828431, 'loss': 'log'}\n",
      "Model with rank: 15\n",
      "Mean validation score: 0.8564 (std: 0.0058)\n",
      "Mean fit time: 2.8215 (std: 0.2542)\n",
      "Mean score time: 0.0240 (std: 0.0039)\n",
      "Parameters: {'alpha': 7.737143309264275e-06, 'l1_ratio': 0.22159760297417408, 'loss': 'log'}\n",
      "Model with rank: 16\n",
      "Mean validation score: 0.8564 (std: 0.0047)\n",
      "Mean fit time: 2.7570 (std: 0.2036)\n",
      "Mean score time: 0.0302 (std: 0.0078)\n",
      "Parameters: {'alpha': 2.2501644769203303e-05, 'l1_ratio': 0.5062419820225736, 'loss': 'hinge'}\n",
      "Model with rank: 17\n",
      "Mean validation score: 0.8563 (std: 0.0062)\n",
      "Mean fit time: 2.8755 (std: 0.2900)\n",
      "Mean score time: 0.0252 (std: 0.0045)\n",
      "Parameters: {'alpha': 3.8287374196910865e-05, 'l1_ratio': 0.4376032906152505, 'loss': 'hinge'}\n",
      "Model with rank: 18\n",
      "Mean validation score: 0.8558 (std: 0.0059)\n",
      "Mean fit time: 2.9038 (std: 0.1402)\n",
      "Mean score time: 0.0282 (std: 0.0028)\n",
      "Parameters: {'alpha': 8.604651757458918e-06, 'l1_ratio': 0.058934929071182696, 'loss': 'log'}\n",
      "Model with rank: 19\n",
      "Mean validation score: 0.8558 (std: 0.0046)\n",
      "Mean fit time: 3.2556 (std: 0.1723)\n",
      "Mean score time: 0.0308 (std: 0.0067)\n",
      "Parameters: {'alpha': 5.852315550232948e-06, 'l1_ratio': 0.4465528452220836, 'loss': 'log'}\n",
      "Model with rank: 20\n",
      "Mean validation score: 0.8557 (std: 0.0052)\n",
      "Mean fit time: 2.6264 (std: 0.2927)\n",
      "Mean score time: 0.0248 (std: 0.0065)\n",
      "Parameters: {'alpha': 4.3852388104286826e-05, 'l1_ratio': 0.3163789400319451, 'loss': 'hinge'}\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(\n",
    "    penalty='elasticnet', \n",
    "    verbose=51,\n",
    "    n_jobs=-1,\n",
    "#     random_state=1724,\n",
    "    early_stopping=True, \n",
    "    class_weight='balanced',\n",
    ")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "    'loss': ['log', 'hinge'], \n",
    "    'alpha': stats.loguniform(1e-6, 1e-4), \n",
    "    'l1_ratio': stats.uniform(0, 1),\n",
    "}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 128\n",
    "random_search = RandomizedSearchCV(\n",
    "        clf, \n",
    "        param_distributions=param_dist, \n",
    "        n_iter=n_iter_search, \n",
    "        scoring='average_precision', \n",
    "        n_jobs=-1, \n",
    "        verbose=51, \n",
    "#         random_state=1727,\n",
    "    )\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f\"RandomizedSearchCV took {time.time() - start:.2f} seconds for {n_iter_search} candidates\")\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "GradientBoostingClassifier(n_iter_no_change=5, verbose=51)\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5873           10.14m\n",
      "         2           0.5682            6.99m\n",
      "         3           0.5539            5.61m\n",
      "         4           0.5423            4.73m\n",
      "         5           0.5344            4.20m\n",
      "         6           0.5275            3.87m\n",
      "         7           0.5206            3.62m\n",
      "         8           0.5128            3.44m\n",
      "         9           0.5048            3.28m\n",
      "        10           0.4999            3.13m\n",
      "        11           0.4957            3.00m\n",
      "        12           0.4870            2.89m\n",
      "        13           0.4830            2.79m\n",
      "        14           0.4773            2.70m\n",
      "        15           0.4707            2.62m\n",
      "        16           0.4670            2.56m\n",
      "        17           0.4642            2.50m\n",
      "        18           0.4598            2.44m\n",
      "        19           0.4540            2.38m\n",
      "        20           0.4514            2.32m\n",
      "        21           0.4488            2.27m\n",
      "        22           0.4446            2.23m\n",
      "        23           0.4425            2.18m\n",
      "        24           0.4384            2.14m\n",
      "        25           0.4365            2.10m\n",
      "        26           0.4339            2.06m\n",
      "        27           0.4317            2.02m\n",
      "        28           0.4287            1.98m\n",
      "        29           0.4249            1.94m\n",
      "        30           0.4230            1.90m\n",
      "        31           0.4212            1.87m\n",
      "        32           0.4195            1.84m\n",
      "        33           0.4163            1.80m\n",
      "        34           0.4146            1.77m\n",
      "        35           0.4129            1.73m\n",
      "        36           0.4113            1.70m\n",
      "        37           0.4099            1.67m\n",
      "        38           0.4084            1.64m\n",
      "        39           0.4056            1.61m\n",
      "        40           0.4040            1.58m\n",
      "        41           0.4027            1.55m\n",
      "        42           0.4006            1.52m\n",
      "        43           0.3994            1.49m\n",
      "        44           0.3981            1.47m\n",
      "        45           0.3966            1.44m\n",
      "        46           0.3944            1.41m\n",
      "        47           0.3932            1.38m\n",
      "        48           0.3919            1.35m\n",
      "        49           0.3896            1.32m\n",
      "        50           0.3880            1.29m\n",
      "        51           0.3865            1.26m\n",
      "        52           0.3855            1.23m\n",
      "        53           0.3844            1.21m\n",
      "        54           0.3833            1.18m\n",
      "        55           0.3811            1.15m\n",
      "        56           0.3800            1.12m\n",
      "        57           0.3791            1.10m\n",
      "        58           0.3780            1.07m\n",
      "        59           0.3765            1.04m\n",
      "        60           0.3745            1.02m\n",
      "        61           0.3734           59.44s\n",
      "        62           0.3724           57.83s\n",
      "        63           0.3713           56.26s\n",
      "        64           0.3703           54.67s\n",
      "        65           0.3694           53.09s\n",
      "        66           0.3678           51.50s\n",
      "        67           0.3670           49.95s\n",
      "        68           0.3654           48.42s\n",
      "        69           0.3645           46.85s\n",
      "        70           0.3637           45.30s\n",
      "        71           0.3626           43.79s\n",
      "        72           0.3611           42.29s\n",
      "        73           0.3604           40.75s\n",
      "        74           0.3597           39.21s\n",
      "        75           0.3585           37.67s\n",
      "        76           0.3578           36.16s\n",
      "        77           0.3571           34.63s\n",
      "        78           0.3561           33.09s\n",
      "        79           0.3551           31.57s\n",
      "        80           0.3544           30.03s\n",
      "        81           0.3536           28.51s\n",
      "        82           0.3529           26.98s\n",
      "        83           0.3522           25.47s\n",
      "        84           0.3514           23.97s\n",
      "        85           0.3507           22.45s\n",
      "        86           0.3497           20.95s\n",
      "        87           0.3489           19.44s\n",
      "        88           0.3481           17.94s\n",
      "        89           0.3475           16.45s\n",
      "        90           0.3469           14.94s\n",
      "        91           0.3456           13.44s\n",
      "        92           0.3449           11.95s\n",
      "        93           0.3441           10.45s\n",
      "        94           0.3435            8.95s\n",
      "        95           0.3429            7.45s\n",
      "        96           0.3421            5.96s\n",
      "        97           0.3414            4.47s\n",
      "        98           0.3408            2.98s\n",
      "        99           0.3394            1.49s\n",
      "       100           0.3389            0.00s\n",
      "train time: 149.1278s\n",
      "predict time: 0.0740s\n",
      "average precision: 0.4738\n",
      "dimensionality: 25850\n",
      "density: 0.007001934235976789\n",
      "top 10 words indicating toxic:\n",
      "['bitch' 'you' 'idiot' 'the' 'suck' 'ass' 'stupid' 'shit' 'fucking' 'fuck']\n",
      "top 10 words indicating not toxic:\n",
      "['00' 'pete' 'petar' 'peta' 'pet' 'pests' 'pesticide' 'pestering' 'pest'\n",
      " 'pessimistic']\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.94      1.00      0.97     27052\n",
      "       toxic       0.94      0.45      0.61      2868\n",
      "\n",
      "    accuracy                           0.94     29920\n",
      "   macro avg       0.94      0.72      0.79     29920\n",
      "weighted avg       0.94      0.94      0.94     29920\n",
      "\n",
      "confusion matrix:\n",
      "[[26972    80]\n",
      " [ 1586  1282]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GradientBoostingClassifier(n_iter_no_change=5, verbose=51),\n",
       " 'GradientBoostingClassifier',\n",
       " 0.47375382756187123,\n",
       " 149.12779235839844,\n",
       " 0.07395434379577637)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(GradientBoostingClassifier(\n",
    "#         random_state=1557,\n",
    "        verbose=51,\n",
    "        n_iter_no_change=5\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "ExtraTreesClassifier(class_weight='balanced', n_estimators=104, n_jobs=-1,\n",
      "                     verbose=51)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "building tree 1 of 104\n",
      "building tree 2 of 104\n",
      "building tree 3 of 104\n",
      "building tree 4 of 104\n",
      "building tree 5 of 104\n",
      "building tree 6 of 104building tree 7 of 104\n",
      "\n",
      "building tree 8 of 104\n",
      "building tree 9 of 104[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   22.6s\n",
      "\n",
      "building tree 10 of 104[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   22.9s\n",
      "\n",
      "building tree 11 of 104[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   23.0s\n",
      "\n",
      "building tree 12 of 104[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   23.0s\n",
      "\n",
      "building tree 13 of 104[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   23.1s\n",
      "\n",
      "building tree 14 of 104[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   23.3s\n",
      "\n",
      "building tree 15 of 104[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   23.3s\n",
      "\n",
      "building tree 16 of 104[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   23.8s\n",
      "\n",
      "building tree 17 of 104[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   46.3s\n",
      "\n",
      "building tree 18 of 104[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   46.4s\n",
      "\n",
      "building tree 19 of 104[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   46.5s\n",
      "\n",
      "building tree 20 of 104[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   46.8s\n",
      "\n",
      "building tree 21 of 104[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   47.0s\n",
      "\n",
      "building tree 22 of 104[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   47.0s\n",
      "\n",
      "building tree 23 of 104[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   47.3s\n",
      "\n",
      "building tree 24 of 104[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   47.6s\n",
      "\n",
      "building tree 25 of 104[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 26 of 104[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 27 of 104[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 28 of 104[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 29 of 104[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 30 of 104[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 31 of 104[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 32 of 104[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 33 of 104[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.5min\n",
      "\n",
      "building tree 34 of 104[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.5min\n",
      "\n",
      "building tree 35 of 104[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  1.5min\n",
      "\n",
      "building tree 36 of 104[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.5min\n",
      "\n",
      "building tree 37 of 104[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.6min\n",
      "\n",
      "building tree 38 of 104[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  1.6min\n",
      "\n",
      "building tree 39 of 104[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  1.6min\n",
      "\n",
      "building tree 40 of 104[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  1.6min\n",
      "\n",
      "building tree 41 of 104[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.9min\n",
      "\n",
      "building tree 42 of 104[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.9min\n",
      "\n",
      "building tree 43 of 104[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  1.9min\n",
      "\n",
      "building tree 44 of 104[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  1.9min\n",
      "\n",
      "building tree 45 of 104[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.0min\n",
      "\n",
      "building tree 46 of 104[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  2.0min\n",
      "\n",
      "building tree 47 of 104[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  2.0min\n",
      "\n",
      "building tree 48 of 104[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  2.0min\n",
      "\n",
      "building tree 49 of 104[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  2.2min\n",
      "\n",
      "building tree 50 of 104[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.2min\n",
      "\n",
      "building tree 51 of 104[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  2.3min\n",
      "\n",
      "building tree 52 of 104[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  2.3min\n",
      "\n",
      "building tree 53 of 104[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  2.3min\n",
      "\n",
      "building tree 54 of 104[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.4min\n",
      "\n",
      "building tree 55 of 104[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  2.4min\n",
      "\n",
      "building tree 56 of 104[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  2.4min\n",
      "\n",
      "building tree 57 of 104[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  2.6min\n",
      "\n",
      "building tree 58 of 104[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  2.7min\n",
      "\n",
      "building tree 59 of 104[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  2.7min\n",
      "\n",
      "building tree 60 of 104[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  2.7min\n",
      "\n",
      "building tree 61 of 104[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  2.8min\n",
      "\n",
      "building tree 62 of 104[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  2.8min\n",
      "\n",
      "building tree 63 of 104[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  2.8min\n",
      "\n",
      "building tree 64 of 104[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.8min\n",
      "\n",
      "building tree 65 of 104[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  3.0min\n",
      "\n",
      "building tree 66 of 104[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  3.0min\n",
      "\n",
      "building tree 67 of 104[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  3.1min\n",
      "\n",
      "building tree 68 of 104[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  3.1min\n",
      "\n",
      "building tree 69 of 104[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  3.2min\n",
      "\n",
      "building tree 70 of 104[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:  3.2min\n",
      "\n",
      "building tree 71 of 104[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:  3.3min\n",
      "\n",
      "building tree 72 of 104[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  3.3min\n",
      "\n",
      "building tree 73 of 104[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  3.4min\n",
      "\n",
      "building tree 74 of 104[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  3.4min\n",
      "\n",
      "building tree 75 of 104[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:  3.5min\n",
      "\n",
      "building tree 76 of 104[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  3.5min\n",
      "\n",
      "building tree 77 of 104[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  3.6min\n",
      "\n",
      "building tree 78 of 104[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:  3.7min\n",
      "\n",
      "building tree 79 of 104[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  3.7min\n",
      "\n",
      "building tree 80 of 104[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  3.7min\n",
      "\n",
      "building tree 81 of 104[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  3.8min\n",
      "\n",
      "building tree 82 of 104[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  3.8min\n",
      "\n",
      "building tree 83 of 104[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:  3.9min\n",
      "\n",
      "building tree 84 of 104[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:  4.0min\n",
      "\n",
      "building tree 85 of 104[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  4.0min\n",
      "\n",
      "building tree 86 of 104[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:  4.1min\n",
      "\n",
      "building tree 87 of 104[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:  4.1min\n",
      "\n",
      "building tree 88 of 104[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:  4.2min\n",
      "\n",
      "building tree 89 of 104[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  4.2min\n",
      "\n",
      "building tree 90 of 104[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  4.2min\n",
      "\n",
      "building tree 91 of 104[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:  4.3min\n",
      "\n",
      "building tree 92 of 104[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  4.4min\n",
      "\n",
      "building tree 93 of 104[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:  4.4min\n",
      "\n",
      "building tree 94 of 104[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  4.5min\n",
      "\n",
      "building tree 95 of 104[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:  4.6min\n",
      "\n",
      "building tree 96 of 104[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  4.6min\n",
      "\n",
      "building tree 97 of 104[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  4.6min\n",
      "\n",
      "building tree 98 of 104\n",
      "building tree 99 of 104\n",
      "building tree 100 of 104[Parallel(n_jobs=-1)]: Done  92 out of 104 | elapsed:  4.7min remaining:   36.9s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 101 of 104\n",
      "building tree 102 of 104\n",
      "building tree 103 of 104[Parallel(n_jobs=-1)]: Done  95 out of 104 | elapsed:  5.0min remaining:   28.2s\n",
      "\n",
      "building tree 104 of 104\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 104 | elapsed:  5.0min remaining:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 101 out of 104 | elapsed:  5.1min remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 104 out of 104 | elapsed:  5.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 104 out of 104 | elapsed:  5.2min finished\n",
      "train time: 311.7794s\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   3 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   6 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  11 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  13 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  14 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  15 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  17 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  19 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  20 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  21 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  22 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  23 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  24 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  27 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  29 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  30 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  31 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  32 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  33 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  35 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  36 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  37 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  38 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  39 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  40 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  41 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  43 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  44 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  46 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  47 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  49 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done  50 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done  51 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done  52 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done  53 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  54 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  55 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  57 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  58 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  59 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  60 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done  61 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done  62 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done  63 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done  64 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done  65 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  66 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  67 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  68 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  70 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  71 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  72 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  73 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done  74 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done  75 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done  76 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done  77 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done  78 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done  79 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done  80 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done  81 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done  83 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done  84 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done  85 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done  86 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done  87 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done  89 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done  92 out of 104 | elapsed:    1.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  95 out of 104 | elapsed:    1.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  98 out of 104 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 101 out of 104 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 104 out of 104 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 104 out of 104 | elapsed:    1.6s finished\n",
      "predict time: 1.8667s\n",
      "average precision: 0.4457\n",
      "dimensionality: 35743\n",
      "density: 0.9158436616959964\n",
      "top 10 words indicating toxic:\n",
      "['to' 'ass' 'bitch' 'suck' 'the' 'stupid' 'shit' 'you' 'fucking' 'fuck']\n",
      "top 10 words indicating not toxic:\n",
      "['canals' 'swaying' 'cladistic' 'clades' 'overy' 'owed' 'swastikanews'\n",
      " 'oxfordshire' 'oxymoronic' 'civilly']\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.94      1.00      0.97     36069\n",
      "       toxic       0.91      0.43      0.58      3824\n",
      "\n",
      "    accuracy                           0.94     39893\n",
      "   macro avg       0.92      0.71      0.78     39893\n",
      "weighted avg       0.94      0.94      0.93     39893\n",
      "\n",
      "confusion matrix:\n",
      "[[35898   171]\n",
      " [ 2173  1651]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ExtraTreesClassifier(class_weight='balanced', n_estimators=104, n_jobs=-1,\n",
       "                      verbose=51),\n",
       " 'ExtraTreesClassifier',\n",
       " 0.44569687217531984,\n",
       " 311.77944111824036,\n",
       " 1.866675853729248)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(ExtraTreesClassifier(\n",
    "        n_estimators=104,\n",
    "        n_jobs=-1,\n",
    "#         random_state=1531,\n",
    "        verbose=51,\n",
    "        class_weight='balanced'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=1e-05, class_weight='balanced', l1_ratio=0.5, loss='log',\n",
      "              n_jobs=-1, penalty='elasticnet', verbose=51)\n",
      "-- Epoch 1\n",
      "Norm: 250.59, NNZs: 6884, Bias: -1.396322, T: 89758, Avg. loss: 0.375892\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 203.96, NNZs: 6087, Bias: -1.657939, T: 179516, Avg. loss: 0.171813\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 185.56, NNZs: 5813, Bias: -1.696660, T: 269274, Avg. loss: 0.164862\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 175.67, NNZs: 5684, Bias: -1.586721, T: 359032, Avg. loss: 0.162456\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 169.32, NNZs: 5603, Bias: -1.600230, T: 448790, Avg. loss: 0.161868\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.78, NNZs: 5579, Bias: -1.635657, T: 538548, Avg. loss: 0.161494\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 161.49, NNZs: 5536, Bias: -1.634185, T: 628306, Avg. loss: 0.160789\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 158.88, NNZs: 5511, Bias: -1.668222, T: 718064, Avg. loss: 0.160768\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 156.85, NNZs: 5500, Bias: -1.638568, T: 807822, Avg. loss: 0.160007\n",
      "Total training time: 0.89 seconds.\n",
      "Convergence after 9 epochs took 0.89 seconds\n",
      "train time: 0.9174s\n",
      "predict time: 0.0050s\n",
      "average precision: 0.5792\n",
      "dimensionality: 25850\n",
      "density: 0.2127659574468085\n",
      "top 10 words indicating toxic:\n",
      "['suck' 'ass' 'asshole' 'crap' 'bullshit' 'idiot' 'stupid' 'shit'\n",
      " 'fucking' 'fuck']\n",
      "top 10 words indicating not toxic:\n",
      "['thank' 'please' 'thanks' 'appreciate' 'interested' 'redirect' 'cheers'\n",
      " 'considered' 'if' 'talk']\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.99      0.95      0.97     27052\n",
      "       toxic       0.65      0.86      0.75      2868\n",
      "\n",
      "    accuracy                           0.94     29920\n",
      "   macro avg       0.82      0.91      0.86     29920\n",
      "weighted avg       0.95      0.94      0.95     29920\n",
      "\n",
      "confusion matrix:\n",
      "[[25745  1307]\n",
      " [  388  2480]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SGDClassifier(alpha=1e-05, class_weight='balanced', l1_ratio=0.5, loss='log',\n",
       "               n_jobs=-1, penalty='elasticnet', verbose=51),\n",
       " 'SGDClassifier',\n",
       " 0.5792448973931088,\n",
       " 0.9174299240112305,\n",
       " 0.004998207092285156)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(SGDClassifier(\n",
    "        loss='log',\n",
    "        penalty='elasticnet',\n",
    "        alpha=1e-5,\n",
    "        l1_ratio=0.5,\n",
    "        n_jobs=-1,\n",
    "#         random_state=0011,\n",
    "        verbose=51,\n",
    "        class_weight='balanced'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=2.5e-05, class_weight='balanced', l1_ratio=0.65, n_jobs=-1,\n",
      "              penalty='elasticnet', verbose=51)\n",
      "-- Epoch 1\n",
      "Norm: 218.05, NNZs: 3329, Bias: -1.060620, T: 89758, Avg. loss: 0.384680\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 183.51, NNZs: 2932, Bias: -0.965976, T: 179516, Avg. loss: 0.183828\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 167.73, NNZs: 2857, Bias: -1.021848, T: 269274, Avg. loss: 0.169453\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 158.15, NNZs: 2825, Bias: -0.951528, T: 359032, Avg. loss: 0.164370\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 151.68, NNZs: 2804, Bias: -0.965878, T: 448790, Avg. loss: 0.162332\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 146.81, NNZs: 2792, Bias: -0.983001, T: 538548, Avg. loss: 0.159860\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 143.17, NNZs: 2820, Bias: -0.945520, T: 628306, Avg. loss: 0.159192\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 140.20, NNZs: 2829, Bias: -0.970348, T: 718064, Avg. loss: 0.158057\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 137.67, NNZs: 2856, Bias: -0.961882, T: 807822, Avg. loss: 0.156676\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 135.59, NNZs: 2863, Bias: -0.958208, T: 897580, Avg. loss: 0.156272\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.83, NNZs: 2876, Bias: -0.956359, T: 987338, Avg. loss: 0.155691\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 132.29, NNZs: 2900, Bias: -0.949827, T: 1077096, Avg. loss: 0.154506\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 130.94, NNZs: 2905, Bias: -0.951093, T: 1166854, Avg. loss: 0.155503\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 129.72, NNZs: 2916, Bias: -0.961517, T: 1256612, Avg. loss: 0.154642\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 128.64, NNZs: 2918, Bias: -0.957811, T: 1346370, Avg. loss: 0.154298\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 127.68, NNZs: 2925, Bias: -0.952379, T: 1436128, Avg. loss: 0.153863\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 126.80, NNZs: 2935, Bias: -0.956627, T: 1525886, Avg. loss: 0.153459\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 17 epochs took 1.37 seconds\n",
      "train time: 1.4014s\n",
      "predict time: 0.0040s\n",
      "average precision: 0.5652\n",
      "dimensionality: 25850\n",
      "density: 0.11353965183752418\n",
      "top 10 words indicating toxic:\n",
      "['sucks' 'suck' 'ass' 'crap' 'bullshit' 'idiot' 'stupid' 'shit' 'fucking'\n",
      " 'fuck']\n",
      "top 10 words indicating not toxic:\n",
      "['thank' 'appreciate' 'please' 'interested' 'thanks' 'learned' 'tired'\n",
      " 'during' 'knowledge' 'promise']\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.99      0.94      0.96     27052\n",
      "       toxic       0.62      0.89      0.73      2868\n",
      "\n",
      "    accuracy                           0.94     29920\n",
      "   macro avg       0.81      0.92      0.85     29920\n",
      "weighted avg       0.95      0.94      0.94     29920\n",
      "\n",
      "confusion matrix:\n",
      "[[25504  1548]\n",
      " [  313  2555]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SGDClassifier(alpha=2.5e-05, class_weight='balanced', l1_ratio=0.65, n_jobs=-1,\n",
       "               penalty='elasticnet', verbose=51),\n",
       " 'SGDClassifier',\n",
       " 0.5652161274583287,\n",
       " 1.4014124870300293,\n",
       " 0.003997802734375)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(SGDClassifier(\n",
    "        loss='hinge',\n",
    "        penalty='elasticnet',\n",
    "        alpha=2.5e-5,\n",
    "        l1_ratio=0.65,\n",
    "        n_jobs=-1,\n",
    "#         random_state=0011,\n",
    "        verbose=51,\n",
    "        class_weight='balanced'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(class_weight='balanced', n_estimators=104, n_jobs=-1,\n",
      "                       verbose=51)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "building tree 1 of 104\n",
      "building tree 2 of 104\n",
      "building tree 3 of 104building tree 4 of 104\n",
      "building tree 5 of 104\n",
      "\n",
      "building tree 6 of 104building tree 7 of 104\n",
      "\n",
      "building tree 8 of 104\n",
      "building tree 9 of 104[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.1s\n",
      "building tree 10 of 104[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.1s\n",
      "\n",
      "\n",
      "building tree 11 of 104[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    7.2s\n",
      "\n",
      "building tree 12 of 104[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    7.3s\n",
      "\n",
      "building tree 13 of 104[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    7.6s\n",
      "\n",
      "building tree 14 of 104[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    7.9s\n",
      "\n",
      "building tree 15 of 104[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    7.9s\n",
      "\n",
      "building tree 16 of 104[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    8.0s\n",
      "\n",
      "building tree 17 of 104[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   14.0s\n",
      "\n",
      "building tree 18 of 104[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.2s\n",
      "\n",
      "building tree 19 of 104[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   14.7s\n",
      "\n",
      "building tree 20 of 104[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   15.0s\n",
      "\n",
      "building tree 21 of 104[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   15.0s\n",
      "\n",
      "building tree 22 of 104[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   15.1s\n",
      "\n",
      "building tree 23 of 104[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   15.2s\n",
      "\n",
      "building tree 24 of 104[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   15.2s\n",
      "\n",
      "building tree 25 of 104[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   20.8s\n",
      "\n",
      "building tree 26 of 104[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   21.3s\n",
      "\n",
      "building tree 27 of 104[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   22.0s\n",
      "\n",
      "building tree 28 of 104[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   22.1s\n",
      "\n",
      "building tree 29 of 104[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   22.1s\n",
      "\n",
      "building tree 30 of 104[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   22.1s\n",
      "\n",
      "building tree 31 of 104[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   22.3s\n",
      "\n",
      "building tree 32 of 104[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   22.6s\n",
      "\n",
      "building tree 33 of 104[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   27.6s\n",
      "\n",
      "building tree 34 of 104[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   27.9s\n",
      "\n",
      "building tree 35 of 104[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   28.4s\n",
      "\n",
      "building tree 36 of 104[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   28.5s\n",
      "\n",
      "building tree 37 of 104[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   28.6s\n",
      "\n",
      "building tree 38 of 104[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   28.8s\n",
      "\n",
      "building tree 39 of 104[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   28.9s\n",
      "\n",
      "building tree 40 of 104[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   29.9s\n",
      "\n",
      "building tree 41 of 104[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   34.4s\n",
      "\n",
      "building tree 42 of 104[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.4s\n",
      "\n",
      "building tree 43 of 104[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   35.5s\n",
      "\n",
      "building tree 44 of 104[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   35.7s\n",
      "\n",
      "building tree 45 of 104[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   36.0s\n",
      "\n",
      "building tree 46 of 104[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   36.1s\n",
      "\n",
      "building tree 47 of 104[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:   36.4s\n",
      "\n",
      "building tree 48 of 104[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   37.4s\n",
      "\n",
      "building tree 49 of 104[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   41.4s\n",
      "\n",
      "building tree 50 of 104[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   42.3s\n",
      "\n",
      "building tree 51 of 104[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   43.1s\n",
      "\n",
      "building tree 52 of 104[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   43.1s\n",
      "\n",
      "building tree 53 of 104[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   43.4s\n",
      "\n",
      "building tree 54 of 104[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   43.9s\n",
      "\n",
      "building tree 55 of 104[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   43.9s\n",
      "\n",
      "building tree 56 of 104[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   45.3s\n",
      "\n",
      "building tree 57 of 104[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   48.5s\n",
      "\n",
      "building tree 58 of 104[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   49.4s\n",
      "\n",
      "building tree 59 of 104[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:   50.0s\n",
      "\n",
      "building tree 60 of 104[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:   50.0s\n",
      "\n",
      "building tree 61 of 104[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   50.8s\n",
      "\n",
      "building tree 62 of 104[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:   50.9s\n",
      "\n",
      "building tree 63 of 104[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:   51.3s\n",
      "\n",
      "building tree 64 of 104[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   51.8s\n",
      "\n",
      "building tree 65 of 104[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   55.3s\n",
      "\n",
      "building tree 66 of 104[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:   55.8s\n",
      "\n",
      "building tree 67 of 104[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:   56.4s\n",
      "\n",
      "building tree 68 of 104[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:   56.5s\n",
      "\n",
      "building tree 69 of 104[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:   57.5s\n",
      "\n",
      "building tree 70 of 104[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:   57.5s\n",
      "\n",
      "building tree 71 of 104[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:   57.7s\n",
      "\n",
      "building tree 72 of 104[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   58.6s\n",
      "\n",
      "building tree 73 of 104[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  1.0min\n",
      "\n",
      "building tree 74 of 104[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.0min\n",
      "\n",
      "building tree 75 of 104[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:  1.0min\n",
      "\n",
      "building tree 76 of 104[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  1.0min\n",
      "\n",
      "building tree 77 of 104[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 78 of 104[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 79 of 104[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 80 of 104[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 81 of 104[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 82 of 104[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  1.1min\n",
      "\n",
      "building tree 83 of 104[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 84 of 104[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 85 of 104[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 86 of 104[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 87 of 104[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 88 of 104[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 89 of 104[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 90 of 104[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.2min\n",
      "\n",
      "building tree 91 of 104[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:  1.3min\n",
      "\n",
      "building tree 92 of 104[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  1.3min\n",
      "\n",
      "building tree 93 of 104[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:  1.3min\n",
      "\n",
      "building tree 94 of 104[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  1.3min\n",
      "\n",
      "building tree 95 of 104[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:  1.3min\n",
      "\n",
      "building tree 96 of 104[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  1.3min\n",
      "\n",
      "building tree 97 of 104[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  1.3min\n",
      "\n",
      "building tree 98 of 104\n",
      "building tree 99 of 104\n",
      "building tree 100 of 104[Parallel(n_jobs=-1)]: Done  92 out of 104 | elapsed:  1.4min remaining:   10.6s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 101 of 104\n",
      "building tree 102 of 104\n",
      "building tree 103 of 104[Parallel(n_jobs=-1)]: Done  95 out of 104 | elapsed:  1.4min remaining:    7.8s\n",
      "\n",
      "building tree 104 of 104\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of 104 | elapsed:  1.5min remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 101 out of 104 | elapsed:  1.5min remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 104 out of 104 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 104 out of 104 | elapsed:  1.5min finished\n",
      "train time: 90.2682s\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  19 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  20 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  21 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  22 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  23 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  24 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  27 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  28 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  29 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  31 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  32 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  33 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  35 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  37 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  38 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  39 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  40 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  41 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  43 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  44 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  47 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  48 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  50 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  51 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  52 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  53 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  54 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  55 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  57 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  58 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  59 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  60 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  61 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  62 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  63 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  64 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  65 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  66 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  67 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  68 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  70 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  71 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  72 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  73 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  74 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  75 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  76 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  77 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  78 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  79 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  80 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  81 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  83 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  84 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  85 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  86 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  87 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  89 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  92 out of 104 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  95 out of 104 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  98 out of 104 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 101 out of 104 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 104 out of 104 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 104 out of 104 | elapsed:    0.6s finished\n",
      "predict time: 0.7355s\n",
      "average precision: 0.3941\n",
      "dimensionality: 25850\n",
      "density: 0.8715280464216635\n",
      "top 10 words indicating toxic:\n",
      "['it' 'in' 'shit' 'for' 'talk' 'to' 'fucking' 'the' 'fuck' 'you']\n",
      "top 10 words indicating not toxic:\n",
      "['predominately' 'ghazi' 'scenarios' 'brenda' 'testimonies' 'gestures'\n",
      " 'breton' 'texan' 'sensors' 'gerald']\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.94      0.99      0.97     27052\n",
      "       toxic       0.86      0.39      0.54      2868\n",
      "\n",
      "    accuracy                           0.94     29920\n",
      "   macro avg       0.90      0.69      0.75     29920\n",
      "weighted avg       0.93      0.94      0.92     29920\n",
      "\n",
      "confusion matrix:\n",
      "[[26868   184]\n",
      " [ 1747  1121]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight='balanced', n_estimators=104, n_jobs=-1,\n",
       "                        verbose=51),\n",
       " 'RandomForestClassifier',\n",
       " 0.3941433243993884,\n",
       " 90.26824879646301,\n",
       " 0.7355427742004395)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(RandomForestClassifier(\n",
    "        n_estimators=104,\n",
    "        n_jobs=-1,\n",
    "#         random_state=0011,\n",
    "        verbose=51,\n",
    "        class_weight='balanced'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB()\n",
      "train time: 0.1070s\n",
      "predict time: 0.0625s\n",
      "average precision: 0.4427\n",
      "dimensionality: 35743\n",
      "density: 1.0\n",
      "top 10 words indicating toxic:\n",
      "['dickface' 'fuckhead' 'fuckface' 'hanibal911you' 'fucka' 'ganna' 'mutha'\n",
      " 'muther' 'zhanzhao' 'motherfucking']\n",
      "top 10 words indicating not toxic:\n",
      "['the' 'to' 'you' 'of' 'and' 'it' 'is' 'that' 'in' 'for']\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not toxic       0.97      0.94      0.95     36069\n",
      "       toxic       0.56      0.75      0.64      3824\n",
      "\n",
      "    accuracy                           0.92     39893\n",
      "   macro avg       0.77      0.84      0.80     39893\n",
      "weighted avg       0.93      0.92      0.92     39893\n",
      "\n",
      "confusion matrix:\n",
      "[[33825  2244]\n",
      " [  967  2857]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ComplementNB(),\n",
       " 'ComplementNB',\n",
       " 0.44269340798660933,\n",
       " 0.10695767402648926,\n",
       " 0.06253981590270996)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(ComplementNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier()\n",
      "train time: 0.0580s\n",
      "predict time: 305.7244s\n",
      "average precision: 0.1134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(KNeighborsClassifier(),\n",
       " 'KNeighborsClassifier',\n",
       " 0.1134408582307221,\n",
       " 0.05796360969543457,\n",
       " 305.72444343566895)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# NMSLIB approximate-nearest neighbors sklearn wrapper\n",
    "# NMSLIB: https://github.com/nmslib/nmslib\n",
    "# Wrapper author: Davi Sidarta-Oliveira\n",
    "# School of Medical Sciences,University of Campinas,Brazil\n",
    "# contact: davisidarta@gmail.com\n",
    "######################################\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from scipy.sparse import csr_matrix, find, issparse\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    import nmslib\n",
    "except ImportError:\n",
    "    print(\"The package 'nmslib' is required. Please install it 'with pip3 install nmslib'.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "class NMSlibTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Wrapper for using nmslib as sklearn's KNeighborsTransformer. This implements\n",
    "    an escalable approximate k-nearest-neighbors graph on spaces defined by nmslib.\n",
    "    Read more about nmslib and its various available metrics at\n",
    "    https://github.com/nmslib/nmslib.\n",
    "    Calling 'nn <- NMSlibTransformer()' initializes the class with\n",
    "     neighbour search parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_neighbors: int (optional, default 30)\n",
    "        number of nearest-neighbors to look for. In practice,\n",
    "        this should be considered the average neighborhood size and thus vary depending\n",
    "        on your number of features, samples and data intrinsic dimensionality. Reasonable values\n",
    "        range from 5 to 100. Smaller values tend to lead to increased graph structure\n",
    "        resolution, but users should beware that a too low value may render granulated and vaguely\n",
    "        defined neighborhoods that arise as an artifact of downsampling. Defaults to 30. Larger\n",
    "        values can slightly increase computational time.\n",
    "    metric: str (optional, default 'cosine')\n",
    "        accepted NMSLIB metrics. Defaults to 'cosine'. Accepted metrics include:\n",
    "        -'sqeuclidean'\n",
    "        -'euclidean'\n",
    "        -'l1'\n",
    "        -'lp' - requires setting the parameter `p`\n",
    "        -'cosine'\n",
    "        -'angular'\n",
    "        -'negdotprod'\n",
    "        -'levenshtein'\n",
    "        -'hamming'\n",
    "        -'jaccard'\n",
    "        -'jansen-shan'\n",
    "    method: str (optional, default 'hsnw')\n",
    "        approximate-neighbor search method. Available methods include:\n",
    "                -'hnsw' : a Hierarchical Navigable Small World Graph.\n",
    "                -'sw-graph' : a Small World Graph.\n",
    "                -'vp-tree' : a Vantage-Point tree with a pruning rule adaptable to non-metric distances.\n",
    "                -'napp' : a Neighborhood APProximation index.\n",
    "                -'simple_invindx' : a vanilla, uncompressed, inverted index, which has no parameters.\n",
    "                -'brute_force' : a brute-force search, which has no parameters.\n",
    "        'hnsw' is usually the fastest method, followed by 'sw-graph' and 'vp-tree'.\n",
    "    n_jobs: int (optional, default 1)\n",
    "        number of threads to be used in computation. Defaults to 1. The algorithm is highly\n",
    "        scalable to multi-threading.\n",
    "    M: int (optional, default 30)\n",
    "        defines the maximum number of neighbors in the zero and above-zero layers during HSNW\n",
    "        (Hierarchical Navigable Small World Graph). However, the actual default maximum number\n",
    "        of neighbors for the zero layer is 2*M.  A reasonable range for this parameter\n",
    "        is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320.\n",
    "        HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib.\n",
    "    efC: int (optional, default 100)\n",
    "        A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph\n",
    "        and leads to higher accuracy of search. However this also leads to longer indexing times.\n",
    "        A reasonable range for this parameter is 50-2000.\n",
    "    efS: int (optional, default 100)\n",
    "        A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the\n",
    "        expense of longer retrieval time. A reasonable range for this parameter is 100-2000.\n",
    "    dense: bool (optional, default False)\n",
    "        Whether to force the algorithm to use dense data, such as np.ndarrays and pandas DataFrames.\n",
    "    Returns\n",
    "    ---------\n",
    "    Class for really fast approximate-nearest-neighbors search.\n",
    "    Example\n",
    "    -------------\n",
    "    import numpy as np\n",
    "    from sklearn.datasets import load_digits\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from dbmap.ann import NMSlibTransformer\n",
    "    #\n",
    "    # Load the MNIST digits data, convert to sparse for speed\n",
    "    digits = load_digits()\n",
    "    data = csr_matrix(digits)\n",
    "    #\n",
    "    # Start class with parameters\n",
    "    nn = NMSlibTransformer()\n",
    "    nn = nn.fit(data)\n",
    "    #\n",
    "    # Obtain kNN graph\n",
    "    knn = nn.transform(data)\n",
    "    #\n",
    "    # Obtain kNN indices, distances and distance gradient\n",
    "    ind, dist, grad = nn.ind_dist_grad(data)\n",
    "    #\n",
    "    # Test for recall efficiency during approximate nearest neighbors search\n",
    "    test = nn.test_efficiency(data)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_neighbors=30,\n",
    "                 metric='cosine',\n",
    "                 method='hnsw',\n",
    "                 n_jobs=10,\n",
    "                 p=None,\n",
    "                 M=30,\n",
    "                 efC=100,\n",
    "                 efS=100,\n",
    "                 dense=False,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.method = method\n",
    "        self.metric = metric\n",
    "        self.n_jobs = n_jobs\n",
    "        self.p = p\n",
    "        self.M = M\n",
    "        self.efC = efC\n",
    "        self.efS = efS\n",
    "        self.space = self.metric\n",
    "\n",
    "        self.dense = dense\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, data, y=None):\n",
    "        # see more metrics in the manual\n",
    "        # https://github.com/nmslib/nmslib/tree/master/manual\n",
    "\n",
    "        if self.dense:\n",
    "            self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                       space=self.space,\n",
    "                                       data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "\n",
    "        else:\n",
    "            if issparse(data) == True:\n",
    "                if self.verbose:\n",
    "                    print('Sparse input. Proceding without converting...')\n",
    "                if isinstance(data, np.ndarray):\n",
    "                    data = csr_matrix(data)\n",
    "            if issparse(data) == False:\n",
    "                if self.verbose:\n",
    "                    print('Input data is ' + str(type(data)) + ' .Converting input to sparse...')\n",
    "                import pandas as pd\n",
    "                if isinstance(data, pd.DataFrame):\n",
    "                    data = csr_matrix(data.values.T)\n",
    "\n",
    "        index_time_params = {'M': self.M, 'indexThreadQty': self.n_jobs, 'efConstruction': self.efC, 'post': 0}\n",
    "\n",
    "        if issparse(data) and (not self.dense) and (not isinstance(data, np.ndarray)):\n",
    "            if self.metric not in ['levenshtein', 'hamming', 'jansen-shan', 'jaccard']:\n",
    "                self.space = {\n",
    "                    'sqeuclidean': 'l2_sparse',\n",
    "                    'euclidean': 'l2_sparse',\n",
    "                    'cosine': 'cosinesimil_sparse_fast',\n",
    "                    'lp': 'lp_sparse',\n",
    "                    'l1_sparse': 'l1_sparse',\n",
    "                    'linf_sparse': 'linf_sparse',\n",
    "                    'angular_sparse': 'angulardist_sparse_fast',\n",
    "                    'negdotprod_sparse': 'negdotprod_sparse_fast',\n",
    "                }[self.metric]\n",
    "                if self.metric == 'lp' and selp.p is None:\n",
    "                    print('Metric set to `lp` but `p` not set. Setting `p` as 0.5.')\n",
    "\n",
    "                if self.metric == 'lp' and selp.p is not None:\n",
    "                    self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                               space=self.space,\n",
    "                                               space_params={'p': self.p},\n",
    "                                               data_type=nmslib.DataType.SPARSE_VECTOR)\n",
    "                else:\n",
    "                    self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                               space=self.space,\n",
    "                                               data_type=nmslib.DataType.SPARSE_VECTOR)\n",
    "            else:\n",
    "                print('Metric ' + self.metric + 'available for string data only. Trying to compute distances...')\n",
    "                data = data.toarray()\n",
    "                self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                           space=self.space,\n",
    "                                           data_type=nmslib.DataType.OBJECT_AS_STRING)\n",
    "        else:\n",
    "            self.space = {\n",
    "                'sqeuclidean': 'l2',\n",
    "                'euclidean': 'l2',\n",
    "                'cosine': 'cosinesimil',\n",
    "                'lp': 'lp',\n",
    "                'l1': 'l1',\n",
    "                'linf': 'linf',\n",
    "                'angular': 'angulardist',\n",
    "                'negdotprod': 'negdotprod',\n",
    "                'levenshtein': 'leven',\n",
    "                'hamming': 'bit_hamming',\n",
    "                'jaccard': 'bit_jaccard',\n",
    "                'jansen-shan': 'jsmetrfastapprox'\n",
    "            }[self.metric]\n",
    "            if self.metric == 'lp':\n",
    "                self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                           space=self.space,\n",
    "                                           space_params={'p': self.p},\n",
    "                                           data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "            else:\n",
    "                self.nmslib_ = nmslib.init(method=self.method,\n",
    "                                           space=self.space,\n",
    "                                           data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "\n",
    "        self.nmslib_.addDataPointBatch(data)\n",
    "        start = time.time()\n",
    "        self.nmslib_.createIndex(index_time_params)\n",
    "        end = time.time()\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Index-time parameters', 'M:', self.M, 'n_threads:', self.n_jobs, 'efConstruction:', self.efC,\n",
    "                  'post:0')\n",
    "            print('Indexing time = %f (sec)' % (end - start))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        start = time.time()\n",
    "        n_samples_transform = data.shape[0]\n",
    "        query_time_params = {'efSearch': self.efS}\n",
    "        if self.verbose:\n",
    "            print('Query-time parameter efSearch:', self.efS)\n",
    "        self.nmslib_.setQueryTimeParams(query_time_params)\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        self.n_neighbors = self.n_neighbors + 1\n",
    "\n",
    "        results = self.nmslib_.knnQueryBatch(data, k=self.n_neighbors,\n",
    "                                             num_threads=self.n_jobs)\n",
    "\n",
    "        indices, distances = zip(*results)\n",
    "        indices, distances = np.vstack(indices), np.vstack(distances)\n",
    "\n",
    "        query_qty = data.shape[0]\n",
    "\n",
    "        if self.metric == 'sqeuclidean':\n",
    "            distances **= 2\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * self.n_neighbors + 1,\n",
    "                           self.n_neighbors)\n",
    "        kneighbors_graph = csr_matrix((distances.ravel(), indices.ravel(),\n",
    "                                       indptr), shape=(n_samples_transform,\n",
    "                                                       n_samples_transform))\n",
    "        end = time.time()\n",
    "        if self.verbose:\n",
    "            print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty, self.n_jobs * float(end - start) / query_qty))\n",
    "\n",
    "        return kneighbors_graph\n",
    "\n",
    "    def ind_dist_grad(self, data, return_grad=True, return_graph=True):\n",
    "\n",
    "        start = time.time()\n",
    "        n_samples_transform = data.shape[0]\n",
    "        query_time_params = {'efSearch': self.efS}\n",
    "        if self.verbose:\n",
    "            print('Query-time parameter efSearch:', self.efS)\n",
    "        self.nmslib_.setQueryTimeParams(query_time_params)\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        self.n_neighbors = self.n_neighbors + 1\n",
    "        results = self.nmslib_.knnQueryBatch(data, k=self.n_neighbors,\n",
    "                                             num_threads=self.n_jobs)\n",
    "        indices, distances = zip(*results)\n",
    "        indices, distances = np.vstack(indices), np.vstack(distances)\n",
    "\n",
    "        query_qty = data.shape[0]\n",
    "\n",
    "        if self.metric == 'sqeuclidean':\n",
    "            distances **= 2\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * self.n_neighbors + 1,\n",
    "                           self.n_neighbors)\n",
    "        kneighbors_graph = csr_matrix((distances.ravel(), indices.ravel(),\n",
    "                                       indptr), shape=(n_samples_transform,\n",
    "                                                       n_samples_transform))\n",
    "        if return_grad:\n",
    "            x, y, dists = find(kneighbors_graph)\n",
    "\n",
    "            # Define gradients\n",
    "            grad = []\n",
    "            if self.metric not in ['sqeuclidean', 'euclidean', 'cosine', 'linf']:\n",
    "                print('Gradient undefined for metric \\'' + self.metric + '\\'. Returning empty array.')\n",
    "\n",
    "            if self.metric == 'cosine':\n",
    "                norm_x = 0.0\n",
    "                norm_y = 0.0\n",
    "                for i in range(x.shape[0]):\n",
    "                    norm_x += x[i] ** 2\n",
    "                    norm_y += y[i] ** 2\n",
    "                if norm_x == 0.0 and norm_y == 0.0:\n",
    "                    grad = np.zeros(x.shape)\n",
    "                elif norm_x == 0.0 or norm_y == 0.0:\n",
    "                    grad = np.zeros(x.shape)\n",
    "                else:\n",
    "                    grad = -(x * dists - y * norm_x) / np.sqrt(norm_x ** 3 * norm_y)\n",
    "\n",
    "            if self.metric == 'euclidean':\n",
    "                grad = x - y / (1e-6 + np.sqrt(dists))\n",
    "\n",
    "            if self.metric == 'sqeuclidean':\n",
    "                grad = x - y / (1e-6 + dists)\n",
    "\n",
    "            if self.metric == 'linf':\n",
    "                result = 0.0\n",
    "                max_i = 0\n",
    "                for i in range(x.shape[0]):\n",
    "                    v = np.abs(x[i] - y[i])\n",
    "                    if v > result:\n",
    "                        result = dists\n",
    "                        max_i = i\n",
    "                grad = np.zeros(x.shape)\n",
    "                grad[max_i] = np.sign(x[max_i] - y[max_i])\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if self.verbose:\n",
    "            print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty, self.n_jobs * float(end - start) / query_qty))\n",
    "\n",
    "        if return_graph and return_grad:\n",
    "            return indices, distances, grad, kneighbors_graph\n",
    "        if return_graph and not return_grad:\n",
    "            return indices, distances, kneighbors_graph\n",
    "        if not return_graph and return_grad:\n",
    "            return indices, distances, grad\n",
    "        if not return_graph and not return_grad:\n",
    "            return indices, distances\n",
    "\n",
    "    def test_efficiency(self, data, data_use=0.1):\n",
    "        \"\"\"Test if NMSlibTransformer and KNeighborsTransformer give same results\n",
    "        \"\"\"\n",
    "        self.data_use = data_use\n",
    "\n",
    "        query_qty = data.shape[0]\n",
    "\n",
    "        (dismiss, test) = train_test_split(data, test_size=self.data_use)\n",
    "        query_time_params = {'efSearch': self.efS}\n",
    "        if self.verbose:\n",
    "            print('Setting query-time parameters', query_time_params)\n",
    "        self.nmslib_.setQueryTimeParams(query_time_params)\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        self.n_neighbors = self.n_neighbors + 1\n",
    "        start = time.time()\n",
    "        ann_results = self.nmslib_.knnQueryBatch(data, k=self.n_neighbors,\n",
    "                                                 num_threads=self.n_jobs)\n",
    "        end = time.time()\n",
    "        if self.verbose:\n",
    "            print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty, self.n_jobs * float(end - start) / query_qty))\n",
    "\n",
    "        # Use sklearn for exact neighbor search\n",
    "        start = time.time()\n",
    "        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors,\n",
    "                                metric='cosine',\n",
    "                                algorithm='brute').fit(data)\n",
    "        knn = nbrs.kneighbors(data)\n",
    "        end = time.time()\n",
    "        if self.verbose:\n",
    "            print('brute-force gold-standart kNN time total=%f (sec), per query=%f (sec)' %\n",
    "                  (end - start, float(end - start) / query_qty))\n",
    "\n",
    "        recall = 0.0\n",
    "        for i in range(0, query_qty):\n",
    "            correct_set = set(knn[1][i])\n",
    "            ret_set = set(ann_results[i][0])\n",
    "            recall = recall + float(len(correct_set.intersection(ret_set))) / len(correct_set)\n",
    "        recall = recall / query_qty\n",
    "        print('kNN recall %f' % recall)\n",
    "\n",
    "    def update_search(self, n_neighbors):\n",
    "        \"\"\"\n",
    "        Updates number of neighbors for kNN distance computation.\n",
    "        Parameters\n",
    "        -----------\n",
    "        n_neighbors: New number of neighbors to look for.\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.datasets import load_digits\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse input. Proceding without converting...\n",
      "Index-time parameters M: 30 n_threads: 8 efConstruction: 100 post:0\n",
      "Indexing time = 195.878053 (sec)\n",
      "Query-time parameter efSearch: 100\n",
      "kNN time total=25.839676 (sec), per query=0.000216 (sec), per query adjusted for thread number=0.001727 (sec)\n",
      "[Pipeline] ............. (step 1 of 2) Processing graph, total= 3.7min\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Miniconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_neighbors_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# The transformer computes the nearest neighbors graph using the maximum number\n",
    "# of neighbors necessary in the grid search. The classifier model filters the\n",
    "# nearest neighbors graph as required by its own n_neighbors parameter.\n",
    "graph_model = NMSlibTransformer(n_neighbors=max(n_neighbors_list), n_jobs=8, verbose=True)\n",
    "classifier_model = KNeighborsClassifier(metric='precomputed', n_jobs=-1)\n",
    "\n",
    "# Note that we give `memory` a directory to cache the graph computation\n",
    "# that will be used several times when tuning the hyperparameters of the\n",
    "# classifier.\n",
    "with TemporaryDirectory(prefix=\"sklearn_graph_cache_\") as tmpdir:\n",
    "    full_model = Pipeline(\n",
    "        steps=[('graph', graph_model), ('classifier', classifier_model)],\n",
    "        memory=tmpdir, verbose=True)\n",
    "    \n",
    "    param_grid = {'classifier__n_neighbors': n_neighbors_list}\n",
    "    grid_model = GridSearchCV(full_model, param_grid, n_jobs=-1, cv=2)\n",
    "    grid_model.fit(X_train, y_train)\n",
    "\n",
    "# Plot the results of the grid search.\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].errorbar(x=n_neighbors_list,\n",
    "                 y=grid_model.cv_results_['mean_test_score'],\n",
    "                 yerr=grid_model.cv_results_['std_test_score'])\n",
    "axes[0].set(xlabel='n_neighbors', title='Classification accuracy')\n",
    "axes[1].errorbar(x=n_neighbors_list, y=grid_model.cv_results_['mean_fit_time'],\n",
    "                 yerr=grid_model.cv_results_['std_fit_time'], color='r')\n",
    "axes[1].set(xlabel='n_neighbors', title='Fit time (with caching)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory='C:\\\\Users\\\\K\\\\AppData\\\\Local\\\\Temp\\\\sklearn_graph_cache_ro7p99ov',\n",
      "         steps=[('graph', NMSlibTransformer(n_jobs=8, verbose=True)),\n",
      "                ('classifier',\n",
      "                 KNeighborsClassifier(metric='precomputed', n_jobs=-1))],\n",
      "         verbose=True)\n",
      "Sparse input. Proceding without converting...\n",
      "Index-time parameters M: 30 n_threads: 8 efConstruction: 100 post:0\n",
      "Indexing time = 172.706257 (sec)\n",
      "Query-time parameter efSearch: 100\n",
      "kNN time total=36.572800 (sec), per query=0.000306 (sec), per query adjusted for thread number=0.002445 (sec)\n",
      "[Pipeline] ............. (step 1 of 2) Processing graph, total= 3.5min\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.1s\n",
      "train time: 210.4915s\n",
      "Query-time parameter efSearch: 100\n",
      "kNN time total=9.999797 (sec), per query=0.000251 (sec), per query adjusted for thread number=0.002005 (sec)\n",
      "predict time: 11.9726s\n",
      "average precision: 0.0995\n"
     ]
    }
   ],
   "source": [
    "graph_model = NMSlibTransformer(n_jobs=8, verbose=True)\n",
    "classifier_model = KNeighborsClassifier(metric='precomputed', n_jobs=-1)\n",
    "with TemporaryDirectory(prefix=\"sklearn_graph_cache_\") as tmpdir:\n",
    "    full_model = Pipeline(\n",
    "        steps=[('graph', graph_model), ('classifier', classifier_model)],\n",
    "        memory=tmpdir, verbose=True)\n",
    "\n",
    "    benchmark(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
